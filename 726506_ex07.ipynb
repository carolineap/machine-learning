{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<br/>\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<center><i><b>\n",
    "Atenção: não são autorizadas cópias, divulgações ou qualquer tipo de uso deste material sem o consentimento prévio dos autores.\n",
    "</center></i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Exercício - Redes Neurais Artificiais </center>\n",
    "\n",
    "Neste exercício, você irá implementar uma rede neural artificial com *backpropagation* que será aplicada na tarefa de reconhecimento de dígitos manuscritos. Antes de iniciar, é fortemente recomendado que você revise o material apresentado em aula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O problema\n",
    "\n",
    "Você foi contratado por uma grande empresa para fazer a identificação correta e automática de quais dígitos estão presentes em um conjunto de imagens. Essas imagens têm dimensão de 20 x 20 pixels, onde cada pixel é representado por um ponto flutuante que indica a intensidade de tons de cinza naquela região.\n",
    "\n",
    "Sabe-se que a aplicação de redes neurais utilizando o algoritmo de *backpropagation* neste tipo de problema obtêm resultados satisfatórios. Assim, seu desafio é implementar tal algoritmo e encontrar os pesos ótimos para que a rede seja capaz de identificar automaticamente os dígitos contidos nas imagens.\n",
    "\n",
    "<center>\n",
    "<div style=\"padding: 0px; float: center;\">\n",
    "    <img src=\"figs/digitos.png\"  style=\"height:400px;\"/> \n",
    "    <center><em>Figura 1. Amostras do conjunto de dados.</em></center>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Carregando e visualizando os dados\n",
    "\n",
    "Nessa etapa, você irá completar a função para plotar os dados. O conjunto que você utilizará será de digitos manuscritos (Figura 1).\n",
    "\n",
    "Cada imagem tem dimensão de 20 x 20 pixels e cada pixel é representado por um ponto flutuante com a intensidade do tom de cinza naquela região. Deste modo, cada amostra é representada pelo desdobramento dos pixels em um vetor com 400 dimensões.\n",
    "\n",
    "O conjunto de dados contém 5.000 amostras, sendo cada amostra representada por um vetor com 400 dimensões. Portanto, o conjunto é representado por uma matriz [5000,400].\n",
    "\n",
    "A segunda parte do conjunto de dados é um vetor $y$ com 5.000 dimensões, o qual contém os rótulos para cada amostra da base de treino. Imagens contendo dígitos de 1 a 9 recebem, respectivamente, classes de 1 a 9, enquanto imagens contendo o dígito 0 são rotuladas como 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos carregar os dados do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np  # importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # importa a biblioteca usada para trabalhar com dataframes (dados em formato de tabela) e análise de dados\n",
    "\n",
    "# importa o arquivo e guarda em um dataframe do Pandas\n",
    "df_dataset = pd.read_csv( 'dados.csv', sep=',', header=None) \n",
    "\n",
    "print('Dados carregados com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos guardar os valores dentro de um array X e as classes dentro de um vetor Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: [10 10 10 10 10]\n",
      "\n",
      "Dimensao de X:  (5000, 400)\n",
      "\n",
      "Dimensao de Y:  (5000,)\n",
      "\n",
      "Classes do problema:  [ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "# Pega os valores das n-1 primeiras colunas e guarda em uma matrix X\n",
    "X = df_dataset.iloc[:, 0:-1].values \n",
    "\n",
    "# Pega os valores da ultima coluna e guarda em um vetor Y\n",
    "Y = df_dataset.iloc[:, -1].values \n",
    "\n",
    "# Imprime as 5 primeiras linhas da matriz X\n",
    "display('X:', X[0:5,:])\n",
    "\n",
    "# Imprime os 5 primeiros valores de Y\n",
    "print('Y:', Y[0:5])\n",
    "\n",
    "print('\\nDimensao de X: ', X.shape)\n",
    "\n",
    "print('\\nDimensao de Y: ', Y.shape)\n",
    "\n",
    "print('\\nClasses do problema: ', np.unique(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar aleatoriamente 100 amostras da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualizaDados(X):\n",
    "    example_width = int(round(np.sqrt(X.shape[1])) )\n",
    "\n",
    "    # Calcula numero de linhas e colunas\n",
    "    m, n = X.shape\n",
    "    example_height = int(n / example_width)\n",
    "\n",
    "    # Calcula numero de itens que serao exibidos\n",
    "    display_rows = int(np.floor(np.sqrt(m)))\n",
    "    display_cols = int(np.ceil(m / display_rows))\n",
    "\n",
    "    fig, axs = plt.subplots(display_rows,display_cols, figsize=(7, 7))\n",
    "                        \n",
    "    for ax, i in zip(axs.ravel(), range( X.shape[0] )):\n",
    "    \n",
    "        new_X = np.reshape( np.ravel(X[i,:]), (example_width, example_height) )\n",
    "\n",
    "        ax.imshow(new_X.T, cmap='gray'); \n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "idx_perm = np.random.permutation( range(X.shape[0]) )\n",
    "visualizaDados( X[idx_perm[0:100],:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Carregando os parâmetros\n",
    "\n",
    "A rede neural proposta para este exercício tem 3 camadas: uma camada de entrada, uma camada oculta e uma camada de saída  (Figura 2). É importante lembrar que a camada de entrada possui 400 neurônios devido ao desdobramento dos pixels das amostras em vetores com 400 dimensões (sem considerar o *bias*, sempre +1).\n",
    "\n",
    "<center>\n",
    "<div style=\"padding: 5px; float: center;\">\n",
    "    <img src=\"figs/nn.png\"  style=\"height:350px;\"/> \n",
    "    <center><em>Figura 2. Arquitetura da rede neural.</em></center>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Inicialmente, você terá acesso aos parâmetros ($\\Theta^{(1)}$, $\\Theta^{(2)}$) de uma rede neural já treinada, armazenados nos arquivos **pesos_Theta1.csv** e **pesos_Theta2.csv**. Tais parâmetros têm dimensões condizentes com uma rede neural com 25 neurônios na camada intermediária e 10 neurônios na camada de saída (correspondente às dez possíveis classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos carregar os pesos pré-treinados para a rede neural e inicializar os parâmetros mais importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando parametros salvos da rede neural...\n",
      "\n",
      "Pesos carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# parametros a serem utilizados neste exercicio\n",
    "input_layer_size  = 400  # 20x20 dimensao das imagens de entrada\n",
    "hidden_layer_size = 25   # 25 neuronios na camada oculta\n",
    "num_labels = 10          # 10 rotulos, de 1 a 10  \n",
    "                         #  (observe que a classe \"0\" recebe o rotulo 10)\n",
    "    \n",
    "print('\\nCarregando parametros salvos da rede neural...\\n')\n",
    "\n",
    "# carregando os pesos da camada 1\n",
    "Theta1 = pd.read_csv('pesos_Theta1.csv', sep=',', header=None).values\n",
    "\n",
    "# carregando os pesos da camada 2\n",
    "Theta2 = pd.read_csv('pesos_Theta2.csv', sep=',', header=None).values\n",
    "\n",
    "# concatena os pesos em um único vetor\n",
    "nn_params = np.concatenate([np.ravel(Theta1), np.ravel(Theta2)])\n",
    "\n",
    "print('Pesos carregados com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Calcula o custo (*Feedforward*)\n",
    "\n",
    "Você precisará implementar a função de custo e gradiente para a rede neural. A função de custo (sem regularização) é descrita a seguir.\n",
    "\n",
    "$$J(\\Theta) = \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K} \\left[-y_k^{(i)} \\log\\left( \\left(h_\\Theta(x^{(i)})\\right)_k \\right) - \\left(1 - y_k^{(i)}\\right) \\log \\left( 1 - \\left(h_\\Theta(x^{(i)} )\\right)_k \\right)\\right]$$\n",
    "\n",
    "Na função $J$, $h_\\Theta(x^{(i)})$ é computado conforme representado na Figura 2. A constante $K$ representa o número de classes. Assim, $h_\\Theta(x^{(i)})_k$ = $a^{(3)}_k$ corresponde à ativação (valor de saída) da $k$-ésima unidade de saída. Também, é importante lembrar que o vetor de saída precisa ser criado a partir da classe original, tornando-se compatível com a rede neural, ou seja, espera-se vetores com 10 posições contendo 1 para o elemento referente à classe esperada e 0 nos demais elementos. Por exemplo, seja 5 o rótulo de determinada amostra, o vetor $Y$ correspondente terá 1 na posição $y_5$ e 0 nas demais posições.\n",
    "\n",
    "Você precisará implementar o algoritmo *feedfoward* para calcular $h_\\Theta(x^{(i)})$ para cada amostra $i$ e somar o custo de todas as amostras. Seu código deverá ser flexível para funcionar com conjuntos de dados de qualquer tamanho e qualquer quantidade de classes, considerando $K \\geq 3$.\n",
    "\n",
    "Nesta fase, implemente a função de custo sem regularização para facilitar a análise. Posteriormente, você implementará o custo regularizado.\n",
    "\n",
    "Antes de implementar a função de custo, você precisará da função sigmoidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid de 0 = 0.500000\n",
      "sigmoid de 10 = 0.999955\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula a função sigmoidal  \n",
    "    \"\"\"\n",
    "\n",
    "    z = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return z\n",
    "\n",
    "# testando a função sigmoidal\n",
    "z = sigmoid(0)\n",
    "print('sigmoid de 0 = %1.6f' %(z))\n",
    "\n",
    "z = sigmoid(10)\n",
    "print('sigmoid de 10 = %1.6f' %(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete a função que será usada para calcular o custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Funcao de custo sem regularizacao ...\n",
      "\n",
      "Custo com os parametros (carregados do arquivo): 0.287629 \n",
      "\n",
      "(este valor deve ser proximo de 0.287629)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def funcaoCusto(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y):\n",
    "    '''\n",
    "    Implementa a funcao de custo para a rede neural com duas camadas\n",
    "    voltada para tarefa de classificacao\n",
    "    \n",
    "    Calcula o custo e gradiente da rede neural. \n",
    "    Os parametros da rede neural sao colocados no vetor nn_params\n",
    "    e precisam ser transformados de volta nas matrizes de peso.\n",
    "    \n",
    "    input_layer_size - tamanho da camada de entrada\n",
    "    hidden_layer_size - tamanho da camada oculta\n",
    "    num_labels - numero de classes possiveis\n",
    "    \n",
    "    O vetor grad de retorno contem todas as derivadas parciais\n",
    "    da rede neural.\n",
    "    '''\n",
    "\n",
    "    # Extrai os parametros de nn_params e alimenta as variaveis Theta1 e Theta2.\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # Qtde de amostras\n",
    "    m = X.shape[0]\n",
    "         \n",
    "    # A variavel a seguir precisa ser retornada corretamente\n",
    "    J = 0;\n",
    "    \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Voce deve completar o codigo a partir daqui \n",
    "    #               acompanhando os seguintes passos.\n",
    "    #\n",
    "    # (1): Lembre-se de transformar os rotulos Y em vetores com 10 posicoes,\n",
    "    #         onde tera zero em todas posicoes exceto na posicao do rotulo\n",
    "    #\n",
    "    # (2): Execute a etapa de feedforward e coloque o custo na variavel J.\n",
    "    #\n",
    "    \n",
    "    rotulos = np.zeros((len(y), num_labels), dtype=int) \n",
    "    for i in range(len(rotulos)):\n",
    "        rotulos[i][y[i] - 1] = 1\n",
    "    \n",
    "    a1 = np.insert(X, 0, np.ones(m, dtype=int), axis=1)\n",
    "    z2 = np.dot(a1, Theta1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.insert(a2, 0, np.ones(a2.shape[0], dtype=int), axis=1)\n",
    "    z3 = np.dot(a2, Theta2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "        \n",
    "    J = np.sum(-rotulos*np.log(a3) - (1 - rotulos)*np.log(1 - a3))/m\n",
    "\n",
    "    ##########################################################################\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "print('\\nFuncao de custo sem regularizacao ...\\n')\n",
    "\n",
    "J = funcaoCusto(nn_params, input_layer_size, hidden_layer_size, num_labels, X, Y)\n",
    "\n",
    "print('Custo com os parametros (carregados do arquivo): %1.6f ' %J)\n",
    "print('\\n(este valor deve ser proximo de 0.287629)\\n')\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Regularização\n",
    "\n",
    "A função de custo com regularização é descrita a seguir.\n",
    "\n",
    "$$J(\\Theta) = \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K} \\left[-y_k^{(i)} \\log\\left( \\left(h_\\Theta(x^{(i)})\\right)_k \\right) - \\left(1 - y_k^{(i)}\\right) \\log \\left( 1 - \\left(h_\\Theta(x^{(i)} )\\right)_k \\right)\\right]$$\n",
    "\n",
    "$$ + \\frac{\\lambda}{2m} \\left[\\sum_{j=1}^{25} \\sum_{k=1}^{400} \\left(\\Theta^{(1)}_{j,k}\\right)^2 + \\sum_{j=1}^{10} \\sum_{k=1}^{25} \\left(\\Theta^{(2)}_{j,k}\\right)^2\\right]$$\n",
    "\n",
    "Você pode assumir que a rede neural terá 3 camadas - uma camada de entrada, uma camada oculta e uma camada de saída. No entanto, seu código deverá ser flexível para suportar qualquer quantidade de neurônios em cada uma dessas camadas. Embora a função $J$ descrita anteriormente contenha números fixos para $\\Theta^{(1)}$ e $\\Theta^{(2)}$, seu código deverá funcionar para outros tamanhos.\n",
    "\n",
    "Também, é importante que a regularização não seja aplicada a termos relacionados aos *bias*. Neste contexto, estes termos estão na primeira coluna de cada matriz $\\Theta^{(1)}$ e $\\Theta^{(2)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, complete a nova função de custo aplicando regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcaoCusto_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, vLambda):\n",
    "    '''\n",
    "    Implementa a funcao de custo para a rede neural com duas camadas\n",
    "    voltada para tarefa de classificacao\n",
    "    \n",
    "    Calcula o custo e gradiente da rede neural. \n",
    "    Os parametros da rede neural sao colocados no vetor nn_params\n",
    "    e precisam ser transformados de volta nas matrizes de peso.\n",
    "    \n",
    "    input_layer_size - tamanho da camada de entrada\n",
    "    hidden_layer_size - tamanho da camada oculta\n",
    "    num_labels - numero de classes possiveis\n",
    "    lambda - parametro de regularizacao\n",
    "    \n",
    "    O vetor grad de retorno contem todas as derivadas parciais\n",
    "    da rede neural.\n",
    "    '''\n",
    "\n",
    "    # Extrai os parametros de nn_params e alimenta as variaveis Theta1 e Theta2.\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # Qtde de amostras\n",
    "    m = X.shape[0]\n",
    "         \n",
    "    # A variavel a seguir precisa ser retornada corretamente\n",
    "    J = 0;\n",
    "    \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Voce deve completar o codigo a partir daqui \n",
    "    #               acompanhando os seguintes passos.\n",
    "    #\n",
    "    # (1): Lembre-se de transformar os rotulos Y em vetores com 10 posicoes,\n",
    "    #         onde tera zero em todas posicoes exceto na posicao do rotulo\n",
    "    #\n",
    "    # (2): Execute a etapa de feedforward e coloque o custo na variavel J.\n",
    "    #\n",
    "    #\n",
    "    # (3): Implemente a regularização na função de custo.\n",
    "    #\n",
    "\n",
    "    J = funcaoCusto(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y)\n",
    "    \n",
    "    reg = (vLambda/(2*m))*(np.sum(Theta1[:, 1:] ** 2) + np.sum(Theta2[:, 1:] ** 2)) \n",
    "    \n",
    "    J += reg\n",
    "    \n",
    "    ##########################################################################\n",
    "\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checando a funcao de custo (c/ regularizacao) ... \n",
      "\n",
      "Custo com os parametros (carregados do arquivo): 0.383770 \n",
      "\n",
      "(este valor deve ser proximo de 0.383770)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecando a funcao de custo (c/ regularizacao) ... \\n')\n",
    "\n",
    "# Parametro de regularizacao dos pesos (aqui sera igual a 1).\n",
    "vLambda = 1;\n",
    "\n",
    "J = funcaoCusto_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, X, Y, vLambda)\n",
    "\n",
    "print('Custo com os parametros (carregados do arquivo): %1.6f ' %J)\n",
    "print('\\n(este valor deve ser proximo de 0.383770)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 5: Inicialização dos parâmetros\n",
    "\n",
    "Nesta parte, começa a implementação das duas camadas da rede neural para classificação dos dígitos manuscritos. Os pesos são inicializados aleatoriamente. Mas, para que toda a execução gere o mesmo resultado, vamos usar uma semente para a função de geração de números aleatórios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inicializando parametros da rede neural...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inicializaPesosAleatorios(L_in, L_out, randomSeed = None):\n",
    "    '''\n",
    "    Inicializa aleatoriamente os pesos de uma camada usando \n",
    "    L_in (conexoes de entrada) e L_out (conexoes de saida).\n",
    "\n",
    "    W sera definido como uma matriz de dimensoes [L_out, 1 + L_in]\n",
    "    visto que devera armazenar os termos para \"bias\".\n",
    "    \n",
    "    randomSeed: indica a semente para o gerador aleatorio\n",
    "    '''\n",
    "\n",
    "    epsilon_init = 0.12\n",
    "    \n",
    "    # se for fornecida uma semente para o gerador aleatorio\n",
    "    if randomSeed is not None:\n",
    "        W = np.random.RandomState(randomSeed).rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "        \n",
    "    # se nao for fornecida uma semente para o gerador aleatorio\n",
    "    else:\n",
    "        W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "        \n",
    "    return W\n",
    "\n",
    "\n",
    "print('\\nInicializando parametros da rede neural...\\n')\n",
    "    \n",
    "initial_Theta1 = inicializaPesosAleatorios(input_layer_size, hidden_layer_size, randomSeed = 10)\n",
    "initial_Theta2 = inicializaPesosAleatorios(hidden_layer_size, num_labels, randomSeed = 20)\n",
    "\n",
    "# junta os pesos iniciais em um unico vetor\n",
    "initial_rna_params = np.concatenate([np.ravel(initial_Theta1), np.ravel(initial_Theta2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6: Backpropagation\n",
    "\n",
    "Nesta parte do exercício, você implementará o algoritmo de *backpropagation* responsável por calcular o gradiente para a função de custo da rede neural. Terminada a implementação do cálculo do gradiente, você poderá treinar a rede neural minimizando a função de custo $J(\\Theta)$ usando um otimizador avançado, como a funcao `minimize` do ScyPy.\n",
    "\n",
    "Primeiro, você precisará implementar o gradiente para a rede neural sem regularização. Após ter verificado que o cálculo do gradiente está correto, você implementará o gradiente para a rede neural com regularização.\n",
    "\n",
    "Você deverá começar pela implementação do gradiente da sigmóide, o qual pode ser calculado utilizando a equação:\n",
    "\n",
    "$$ g'(z) = \\frac{d}{dz}g(z) = g(z)(1-g(z)), $$\n",
    "\n",
    "sendo que\n",
    "\n",
    "$$ g(z) = \\frac{1}{1 + e^{-z}}. $$\n",
    "\n",
    "Ao completar, teste diferentes valores para a função `sigmoidGradient`. Para valores grandes de *z* (tanto positivo, quanto negativo), o resultado deve ser próximo a zero. Quando $z = 0$, o resultado deve ser exatamente 0,25. A função deve funcionar com vetores e matrizes também. No caso de matrizes, a função deve calcular o gradiente para cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliando o gradiente da sigmoide...\n",
      "\n",
      "Gradiente da sigmoide avaliado em [1 -0.5 0 0.5 1]:\n",
      "\n",
      "[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n",
      "\n",
      "Se sua implementacao estiver correta, o gradiente da sigmoide sera:\n",
      "[0.19661193 0.23500371 0.25 0.23500371 0.19661193]:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sigmoidGradient(z):\n",
    "    '''\n",
    "    Retorna o gradiente da funcao sigmoidal para z \n",
    "    \n",
    "    Calcula o gradiente da funcao sigmoidal\n",
    "    para z. A funcao deve funcionar independente se z for matriz ou vetor.\n",
    "    Nestes casos,  o gradiente deve ser calculado para cada elemento.\n",
    "    '''\n",
    "    \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Calcula o gradiente da funcao sigmoidal para \n",
    "    #           cada valor de z (seja z matriz, escalar ou vetor).\n",
    "    #\n",
    "\n",
    "    g = sigmoid(z)*(1 - sigmoid(z))    \n",
    "       \n",
    "    ##########################################################################\n",
    "\n",
    "    return g\n",
    "\n",
    "print('\\nAvaliando o gradiente da sigmoide...\\n')\n",
    "\n",
    "g = sigmoidGradient(np.array([1,-0.5, 0, 0.5, 1]))\n",
    "print('Gradiente da sigmoide avaliado em [1 -0.5 0 0.5 1]:\\n')\n",
    "print(g)\n",
    "\n",
    "print('\\nSe sua implementacao estiver correta, o gradiente da sigmoide sera:')\n",
    "print('[0.19661193 0.23500371 0.25 0.23500371 0.19661193]:\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo do algoritmo *backpropagation* é encontrar a \"parcela de responsabilidade\" que cada neurônio da rede neural teve com o erro gerado na saída. Dada uma amostra de treino ($x^{(t)}, y^{(t)}$), primeiro é executado o passo de *feedforward* para calcular todas as ativações na rede, incluindo o valor de saída $h_{\\Theta}(x)$. Posteriormente, para cada neurônio $j$ na camada $l$, é calculado o \"erro\" $\\delta_{j}^{(l)}$ que mede o quanto determinado neurônio contribuiu para a diferença entre o valor esperado e o valor obtido na saída da rede.\n",
    "\n",
    "<center>\n",
    "<div style=\"padding: 5px; float: center;\">\n",
    "    <img src=\"figs/nn_back.png\"  style=\"height:350px;\"/> \n",
    "    <center><em>Figura 3. Arquitetura da rede neural.</em></center>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Nos neurônios de saída, a diferença pode ser medida entre o valor esperado (rótulo da amostra) e o valor obtido (a ativação final da rede), onde tal diferença será usada para definir $\\delta_{j}^{(3)}$ (visto que a camada 3 é a última). Nas camadas ocultas (quando houver mais de uma), o termo $\\delta_{j}^{(l)}$ será calculado com base na média ponderada dos erros encontrados na camada posterior ($l + 1$).\n",
    "\n",
    "A seguir, é descrito em detalhes como a implementação do algoritmo *backpropagation* deve ser feita. Você precisará seguir os passos 1 a 4 dentro de um laço, processando uma amostra por vez. No passo 5, o gradiente acumulado é dividido pelas *m* amostras, o qual será utilizado na função de custo da rede neural.\n",
    "\n",
    " 1. Coloque os valores na camada de entrada ($a^{(1)}$) para a amostra de treino a ser processada. Calcule as ativações das camadas 2 e 3 utilizando o passo de *feedforward*. Observe que será necessário adicionar um termo $+1$ para garantir que os vetores de ativação das camadas ($a^{(1)}$) e ($a^{(2)}$) também incluam o neurônio de *bias*.\n",
    " \n",
    " 2. Para cada neurônio $k$ na camada 3 (camada de saída), defina:\n",
    "    $$ \\delta_{k}^{(3)} = (a^{(3)}_k - y_k), $$\n",
    "    onde $y_k \\in \\{0,1\\}$ indica se a amostra sendo processada pertence a classe $k$ ($y_k = 1$) ou não ($y_k = 0$).\n",
    "    \n",
    " 3. Para a camada oculta $l$ = 2, defina:\n",
    "\n",
    "    $$ \\delta^{(2)} = (\\Theta^{(2)})^T \\delta^{(3)}*g'(z^{(2)}) $$\n",
    "    \n",
    " 4. Acumule o gradiente usando a fórmula descrita a seguir. Lembre-se de não utilizar o valor associado ao bias $\\delta^{(2)}_0$.\n",
    "    \n",
    "    $$ \\Delta^{(l)} = \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)})^T $$\n",
    "    \n",
    " 5. Obtenha o gradiente sem regularização para a função de custo da rede neural dividindo os gradientes acumulados por $\\frac{1}{m}$:\n",
    " \n",
    "     $$ D^{(l)}_{ij} = \\frac{1}{m}\\Delta^{(l)}_{ij} $$\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "Neste ponto, você deverá implementar o algoritmo de *backpropagation*. Crie uma nova função de custo, baseada na função implementada anteriormente, que retorne as derivadas parciais dos parâmetros. Nesta função, você precisará implementar o gradiente para a rede neural sem regularização.\n",
    "\n",
    "Logo após a função que implementa o algoritmo de *backpropagation*, é chamada uma outra função que fará a checagem do gradiente. O código dessa função está no arquivo **utils.py** que está localizado na pasta raíz desse exercício. Esta checagem tem o propósito de certificar que seu código calcula o gradiente corretamente. Neste passo, se sua implementação estiver correta, você deverá ver uma diferença **menor que 1e-9**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.27220311e-02  1.27220311e-02]\n",
      " [ 1.58832811e-04  1.58832809e-04]\n",
      " [ 2.17690452e-04  2.17690455e-04]\n",
      " [ 7.64045027e-05  7.64045009e-05]\n",
      " [ 6.46352264e-03  6.46352265e-03]\n",
      " [ 2.34983744e-05  2.34983735e-05]\n",
      " [-3.74199116e-05 -3.74199098e-05]\n",
      " [-6.39344977e-05 -6.39345006e-05]\n",
      " [-5.74199923e-03 -5.74199923e-03]\n",
      " [-1.34052021e-04 -1.34052019e-04]\n",
      " [-2.59146269e-04 -2.59146269e-04]\n",
      " [-1.45982635e-04 -1.45982634e-04]\n",
      " [-1.26792390e-02 -1.26792390e-02]\n",
      " [-1.67913183e-04 -1.67913187e-04]\n",
      " [-2.41809017e-04 -2.41809017e-04]\n",
      " [-9.33867539e-05 -9.33867522e-05]\n",
      " [-7.94573534e-03 -7.94573535e-03]\n",
      " [-4.76254503e-05 -4.76254501e-05]\n",
      " [-2.64923639e-06 -2.64923844e-06]\n",
      " [ 4.47626736e-05  4.47626708e-05]\n",
      " [ 1.09347722e-01  1.09347722e-01]\n",
      " [ 5.67965185e-02  5.67965185e-02]\n",
      " [ 5.25298306e-02  5.25298306e-02]\n",
      " [ 5.53542907e-02  5.53542907e-02]\n",
      " [ 5.59290833e-02  5.59290833e-02]\n",
      " [ 5.23534682e-02  5.23534682e-02]\n",
      " [ 1.08133003e-01  1.08133003e-01]\n",
      " [ 5.67319602e-02  5.67319602e-02]\n",
      " [ 5.14442931e-02  5.14442931e-02]\n",
      " [ 5.48296085e-02  5.48296085e-02]\n",
      " [ 5.56926532e-02  5.56926532e-02]\n",
      " [ 5.11795651e-02  5.11795651e-02]\n",
      " [ 3.06270372e-01  3.06270372e-01]\n",
      " [ 1.59463135e-01  1.59463135e-01]\n",
      " [ 1.45570264e-01  1.45570264e-01]\n",
      " [ 1.56700533e-01  1.56700533e-01]\n",
      " [ 1.56043968e-01  1.56043968e-01]\n",
      " [ 1.45771544e-01  1.45771544e-01]]\n",
      "As duas colunas acima deve ser bem semelhantes.\n",
      "(Esquerda - Gradiente numerico, Direita - Seu gradiente)\n",
      "\n",
      "Se sua implementacao de backpropagation esta correta, \n",
      "a diferenca relativa devera ser pequena (menor que 1e-9). \n",
      "\n",
      "Diferenca relativa: 2.0185e-11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def funcaoCusto_backp(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y):\n",
    "    '''\n",
    "    Implementa a funcao de custo para a rede neural com tres camadas\n",
    "    voltada para a tarefa de classificacao\n",
    "    \n",
    "    Calcula o custo e gradiente da rede neural. \n",
    "    Os parametros da rede sao colocados no vetor nn_params\n",
    "    e precisam ser transformados de volta nas matrizes de peso.\n",
    "    \n",
    "    input_layer_size - tamanho da camada de entrada\n",
    "    hidden_layer_size - tamanho da camada oculta\n",
    "    num_labels - numero de classes possiveis\n",
    "    lambda - parametro de regularizacao\n",
    "    \n",
    "    O vetor grad de retorno contem todas as derivadas parciais\n",
    "    da rede neural.\n",
    "    '''\n",
    "\n",
    "    # Extrai os parametros de nn_params e alimenta as variaveis Theta1 e Theta2.\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # Qtde de amostras\n",
    "    m = X.shape[0]\n",
    "         \n",
    "    # As variaveis a seguir precisam ser retornadas corretamente\n",
    "    J = 0;\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Voce deve completar o codigo a partir daqui \n",
    "    #               acompanhando os seguintes passos.\n",
    "    #\n",
    "    # (1): Lembre-se de transformar os rotulos Y em vetores com 10 posicoes,\n",
    "    #         onde tera zero em todas posicoes exceto na posicao do rotulo\n",
    "    #\n",
    "    # (2): Execute a etapa de feedforward e coloque o custo na variavel J.\n",
    "    #\n",
    "    # (3): Implemente o algoritmo de backpropagation para calcular \n",
    "    #      os gradientes e alimentar as variaveis Theta1_grad e Theta2_grad.\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    rotulos = np.zeros((len(y), num_labels), dtype=int) \n",
    "    for i in range(len(rotulos)):\n",
    "        rotulos[i][y[i] - 1] = 1\n",
    "\n",
    "    a1 = np.insert(X, 0, np.ones(m, dtype=int), axis=1)\n",
    "    z2 = np.dot(a1, Theta1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.insert(a2, 0, np.ones(a2.shape[0], dtype=int), axis=1)\n",
    "    z3 = np.dot(a2, Theta2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    \n",
    "    delta3 = a3 - rotulos\n",
    "    delta2 = np.dot(delta3, Theta2[:, 1:]) * sigmoidGradient(z2)\n",
    "\n",
    "    Theta1_grad = np.dot(delta2.T, a1)/m\n",
    "    Theta2_grad = np.dot(delta3.T, a2)/m\n",
    "    \n",
    "    \n",
    "    J = np.sum(-rotulos*np.log(a3) - (1 - rotulos)*np.log(1 - a3))/m\n",
    "\n",
    "    \n",
    "    ##########################################################################\n",
    "\n",
    "    # Junta os gradientes\n",
    "    grad = np.concatenate([np.ravel(Theta1_grad), np.ravel(Theta2_grad)])\n",
    "\n",
    "    return J, grad\n",
    "\n",
    "# executa o arquivo que contem a funca que faz a checagem do gradiente\n",
    "%run utils.py\n",
    "verificaGradiente(funcaoCusto_backp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 7: Outra parte da regularização\n",
    "\n",
    "Agora, a regularização deverá ser adicionada após se calcular o gradiente durante o algoritmo de *backpropagation*. Lembre-se que a regularização não é adicionada quando $j = 0$, ou seja, na primeira coluna de $\\Theta$. Portanto, para $j \\geq 1$, o gradiente é descrito como:\n",
    "\n",
    "$$ D^{(l)}_{ij} = \\frac{1}{m}\\Delta^{(l)}_{ij} + \\frac{\\lambda}{m}\\Theta^{(l)}_{ij} $$\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Você deverá criar uma nova função de custo que é uma atualização da função anterior, mas com regularização e gradiente.\n",
    "\n",
    "Logo após a função que implementa o algoritmo de *backpropagation* com regularização, a função que faz a checagem do gradiente será chamada novamente. Se sua implementação estiver correta, você deverá ver uma diferença **menor que 1e-9**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01272203  0.01272203]\n",
      " [ 0.05471668  0.05471668]\n",
      " [ 0.00868489  0.00868489]\n",
      " [-0.04533175 -0.04533175]\n",
      " [ 0.00646352  0.00646352]\n",
      " [-0.01674143 -0.01674143]\n",
      " [ 0.03938178  0.03938178]\n",
      " [ 0.05929756  0.05929756]\n",
      " [-0.005742   -0.005742  ]\n",
      " [-0.03277532 -0.03277532]\n",
      " [-0.06025856 -0.06025856]\n",
      " [-0.03234036 -0.03234036]\n",
      " [-0.01267924 -0.01267924]\n",
      " [ 0.05926853  0.05926853]\n",
      " [ 0.03877546  0.03877546]\n",
      " [-0.01736759 -0.01736759]\n",
      " [-0.00794574 -0.00794574]\n",
      " [-0.04510686 -0.04510686]\n",
      " [ 0.00898998  0.00898998]\n",
      " [ 0.05482148  0.05482148]\n",
      " [ 0.10934772  0.10934772]\n",
      " [ 0.11135436  0.11135436]\n",
      " [ 0.06099703  0.06099703]\n",
      " [ 0.00994614  0.00994614]\n",
      " [-0.00160637 -0.00160637]\n",
      " [ 0.03558854  0.03558854]\n",
      " [ 0.108133    0.108133  ]\n",
      " [ 0.11609346  0.11609346]\n",
      " [ 0.0761714   0.0761714 ]\n",
      " [ 0.02218834  0.02218834]\n",
      " [-0.00430676 -0.00430676]\n",
      " [ 0.01898519  0.01898519]\n",
      " [ 0.30627037  0.30627037]\n",
      " [ 0.21889958  0.21889958]\n",
      " [ 0.18458753  0.18458753]\n",
      " [ 0.13942633  0.13942633]\n",
      " [ 0.09836012  0.09836012]\n",
      " [ 0.10071231  0.10071231]]\n",
      "As duas colunas acima deve ser bem semelhantes.\n",
      "(Esquerda - Gradiente numerico, Direita - Seu gradiente)\n",
      "\n",
      "Se sua implementacao de backpropagation esta correta, \n",
      "a diferenca relativa devera ser pequena (menor que 1e-9). \n",
      "\n",
      "Diferenca relativa: 1.91899e-11\n",
      "\n",
      "\n",
      "\n",
      "Checando a funcao de custo (c/ regularizacao) ... \n",
      "\n",
      "Custo com os parametros (carregados do arquivo): 0.576051\n",
      "\n",
      "(este valor deve ser proximo de 0.576051 (para lambda = 3))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def funcaoCusto_backp_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, vLambda):\n",
    "    '''\n",
    "    Implementa a funcao de custo para a rede neural com tres camadas\n",
    "    voltada para tarefa de classificacao\n",
    "    \n",
    "    Calcula o custo e gradiente da rede neural. \n",
    "    Os parametros da rede neural sao colocados no vetor nn_params\n",
    "    e precisam ser transformados de volta nas matrizes de peso.\n",
    "    \n",
    "    input_layer_size - tamanho da camada de entrada\n",
    "    hidden_layer_size - tamanho da camada oculta\n",
    "    num_labels - numero de classes possiveis\n",
    "    lambda - parametro de regularizacao\n",
    "    \n",
    "    O vetor grad de retorno contem todas as derivadas parciais\n",
    "    da rede neural.\n",
    "    '''\n",
    "\n",
    "    # Extrai os parametros de nn_params e alimenta as variaveis Theta1 e Theta2.\n",
    "    Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "    Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "    # Qtde de amostras\n",
    "    m = X.shape[0]\n",
    "         \n",
    "    # As variaveis a seguir precisam ser retornadas corretamente\n",
    "    J = 0;\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ########################\n",
    "    # Instrucoes: Voce deve completar o codigo a partir daqui \n",
    "    #               acompanhando os seguintes passos.\n",
    "    #\n",
    "    # (1): Lembre-se de transformar os rotulos Y em vetores com 10 posicoes,\n",
    "    #         onde tera zero em todas posicoes exceto na posicao do rotulo\n",
    "    #\n",
    "    # (2): Execute a etapa de feedforward e coloque o custo na variavel J.\n",
    "    #\n",
    "    # (3): Implemente o algoritmo de backpropagation para calcular \n",
    "    #      os gradientes e alimentar as variaveis Theta1_grad e Theta2_grad.\n",
    "    #\n",
    "    # (4): Implemente a regularização na função de custo e gradiente.\n",
    "    #\n",
    "    \n",
    "    rotulos = np.zeros((len(y), num_labels), dtype=int) \n",
    "    for i in range(len(rotulos)):\n",
    "        rotulos[i][y[i] - 1] = 1\n",
    "        \n",
    "    a1 = np.insert(X, 0, np.ones(m, dtype=int), axis=1)\n",
    "    z2 = np.dot(a1, Theta1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.insert(a2, 0, np.ones(a2.shape[0], dtype=int), axis=1)\n",
    "    z3 = np.dot(a2, Theta2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    J = 1/m * np.sum(-rotulos*np.log(a3) - (1 - rotulos)*np.log(1 - a3))\n",
    "    \n",
    "    reg = (vLambda/(2*m))*(np.sum(Theta1[:, 1:] ** 2) + np.sum(Theta2[:, 1:] ** 2)) \n",
    "\n",
    "    J += reg\n",
    "    \n",
    "    delta3 = a3 - rotulos\n",
    "    delta2 = np.dot(delta3, Theta2[:, 1:]) * sigmoidGradient(z2)\n",
    "    \n",
    "    Theta1_grad[:, 0] = (np.dot(delta2.T, a1)[:, 0]/m) \n",
    "    Theta1_grad[:, 1:] = (np.dot(delta2.T, a1)[:, 1:]/m) + (vLambda/m)*Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad[:, 0] = (np.dot(delta3.T, a2)[:, 0]/m) \n",
    "    Theta2_grad[:, 1:] = (np.dot(delta3.T, a2)[:, 1:]/m) + (vLambda/m)*Theta2[:, 1:]\n",
    "    \n",
    "    \n",
    "    ##########################################################################\n",
    "\n",
    "    # Junta os gradientes\n",
    "    grad = np.concatenate([np.ravel(Theta1_grad), np.ravel(Theta2_grad)])\n",
    "\n",
    "    return J, grad\n",
    "\n",
    "\n",
    "# Parametro de regularizacao dos pesos.\n",
    "vLambda = 3;\n",
    "\n",
    "\n",
    "# executa o arquivo que contem a funca que faz a checagem do gradiente. \n",
    "# Desa vez o valor de lambda tambem e informado\n",
    "%run utils.py\n",
    "verificaGradiente(funcaoCusto_backp_reg, vLambda=vLambda)\n",
    "\n",
    "\n",
    "print('\\n\\nChecando a funcao de custo (c/ regularizacao) ... \\n')\n",
    "\n",
    "J, grad = funcaoCusto_backp_reg(nn_params, input_layer_size, hidden_layer_size, num_labels, X, Y, vLambda)\n",
    "\n",
    "print('Custo com os parametros (carregados do arquivo): %1.6f' %J)\n",
    "print('\\n(este valor deve ser proximo de 0.576051 (para lambda = 3))\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 8: Treinando a rede neural\n",
    "\n",
    "Neste ponto, todo o código necessário para treinar a rede está pronto.\n",
    "Aqui, será utilizada a funcao `minimize` do ScyPy para treinar as funções de custo\n",
    "de forma eficiente utilizando os gradientes calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando a rede neural.......\n",
      ".......(Aguarde, pois esse processo por ser um pouco demorado.)\n",
      "\n",
      "     fun: 0.3178021020232608\n",
      "     jac: array([-1.08369174e-05, -2.01299580e-08,  2.00087132e-08, ...,\n",
      "       -4.03386352e-06,  3.88587452e-05, -7.91108901e-07])\n",
      " message: 'Max. number of function evaluations reached'\n",
      "    nfev: 500\n",
      "     nit: 29\n",
      "  status: 3\n",
      " success: False\n",
      "       x: array([-8.86951059e-01, -1.00649790e-04,  1.00043566e-04, ...,\n",
      "        7.41677935e-02,  2.31758748e+00,  1.03674639e+00])\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.optimize\n",
    "\n",
    "print('\\nTreinando a rede neural.......')\n",
    "print('.......(Aguarde, pois esse processo por ser um pouco demorado.)\\n')\n",
    "\n",
    "# Apos ter completado toda a tarefa, mude o parametro MaxIter para\n",
    "# um valor maior e verifique como isso afeta o treinamento.\n",
    "MaxIter = 500\n",
    "\n",
    "# Voce tambem pode testar valores diferentes para lambda.\n",
    "vLambda = 1\n",
    "\n",
    "# Minimiza a funcao de custo\n",
    "result = scipy.optimize.minimize(fun=funcaoCusto_backp_reg, x0=initial_rna_params, args=(input_layer_size, hidden_layer_size, num_labels, X, Y, vLambda),  \n",
    "                method='TNC', jac=True, options={'maxiter': MaxIter})\n",
    "\n",
    "# Coleta os pesos retornados pela função de minimização\n",
    "nn_params = result.x\n",
    "\n",
    "# Obtem Theta1 e Theta2 back a partir de rna_params\n",
    "Theta1 = np.reshape( nn_params[0:hidden_layer_size*(input_layer_size + 1)], (hidden_layer_size, input_layer_size+1) )\n",
    "Theta2 = np.reshape( nn_params[ hidden_layer_size*(input_layer_size + 1):], (num_labels, hidden_layer_size+1) )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 9: Visualizando os pesos\n",
    "\n",
    "\n",
    "Uma das formas de entender o que a rede neural está aprendendo, é visualizar a representação capturada nos neurônios da camada oculta. Informalmente, dado um neurônio de uma camada oculta qualquer, uma das formas de visualizar o que esse neurônio calcula, é encontrar uma entrada *x* que o fará ser ativado (ou seja, um resultado próximo a 1). Para a rede neural que foi treinada, perceba que a $i$-ésima linha de $\\Theta^{(1)}$ é um vetor com 401 dimensões, o qual representa os parâmetros para o $i$-ésimo neurônio. Se descartarmos o termo *bias*, teremos um vetor de 400 dimensões que representa o peso para cada pixel a partir da camada de entrada. Deste modo, uma das formas de visualizar a representação capturada pelo neurônio da camada oculta, é reorganizar essas 400 dimensões em uma imagem de 20 x 20 pixels e exibi-la. \n",
    "\n",
    "O script a seguir irá exibir uma imagem com 25 unidades, cada uma correspondendo a um neurônio da camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizando a rede neural... \n",
      "\n",
      "(5000, 400)\n",
      "(25, 400)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\nVisualizando a rede neural... \\n')\n",
    "\n",
    "print(X.shape)\n",
    "print(Theta1[:, 1:].shape)\n",
    "\n",
    "visualizaDados(Theta1[:, 1:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 10: Predição\n",
    "\n",
    "Após treinar a rede neural, ela será utilizada para predizer\n",
    "os rótulos das amostras. Neste ponto, foi implementada a função de predição\n",
    "para que a rede neural seja capaz de prever os rótulos no conjunto de dados\n",
    "e calcular a acurácia do método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acuracia no conjunto de treinamento: 99.520000\n",
      "\n",
      "\n",
      "Acuracia esperada: 99.56% (aproximadamente)\n"
     ]
    }
   ],
   "source": [
    "def predicao(Theta1, Theta2, X):\n",
    "    '''\n",
    "    Prediz o rotulo de uma amostra apresentada a rede neural\n",
    "    \n",
    "    Prediz o rotulo de X ao utilizar\n",
    "    os pesos treinados na rede neural (Theta1, Theta2)\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0] # número de amostras\n",
    "    num_labels = Theta2.shape[0]\n",
    "    \n",
    "    p = np.zeros(m)\n",
    "\n",
    "    a1 = np.hstack( [np.ones([m,1]),X] )\n",
    "    h1 = sigmoid( np.dot(a1,Theta1.T) )\n",
    "\n",
    "    a2 = np.hstack( [np.ones([m,1]),h1] ) \n",
    "    h2 = sigmoid( np.dot(a2,Theta2.T) )\n",
    "    \n",
    "    p = np.argmax(h2,axis=1)\n",
    "    p = p+1\n",
    "    \n",
    "    return p\n",
    "    \n",
    "\n",
    "pred = predicao(Theta1, Theta2, X)\n",
    "\n",
    "print('\\nAcuracia no conjunto de treinamento: %f\\n'%( np.mean( pred == Y ) * 100) )\n",
    "\n",
    "print('\\nAcuracia esperada: 99.56% (aproximadamente)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
